{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4793c704-6b3e-4b45-863a-d671801bf6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Module: null prototype] { default: {} }"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import \"dotenv/config\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adde1c14",
   "metadata": {},
   "source": [
    "## Basic Building blocks\n",
    "\n",
    " LangChain.js provides a convenient way to send prompts to language models and retrieve responses, making it ideal for developing applications that require natural language processing. By leveraging the capabilities of OpenAI's language models, you can create sophisticated natural language processing applications with relative ease.\n",
    "\n",
    "### Code Walkthrough\n",
    "Let's walk through a simple example step-by-step. We'll start by setting up the necessary imports and creating a connection to the OpenAI language model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212ff0fb",
   "metadata": {},
   "source": [
    "#### Importing the ChatOpenAI Class\n",
    "This line imports the ChatOpenAI class from the @langchain/openai package. The ChatOpenAI class is designed to facilitate interactions with OpenAI's language models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d460c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5b1337",
   "metadata": {},
   "source": [
    "#### Creating an Instance of ChatOpenAI\n",
    "Here, we create an instance of the ChatOpenAI class. We pass an object with a modelName property to the constructor. The modelName specifies which version of the OpenAI model we want to use. In this case, we are using `gpt-4o`, which refers to a specific variant of the GPT-4 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a42a5eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "const model = new ChatOpenAI({\n",
    "  modelName: \"gpt-4o\",\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57a229e",
   "metadata": {},
   "source": [
    "#### Sending a Prompt to the Model\n",
    "This line sends a prompt to the OpenAI model using the invoke method. The prompt here is \"Ge mig ett gott råd\", which is Swedish for \"Give me some good advice\". The await keyword ensures that we wait for the model's response before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8262c183",
   "metadata": {},
   "outputs": [],
   "source": [
    "const response = await model.invoke('Ge mig ett gott råd');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc77e05",
   "metadata": {},
   "source": [
    "#### Printing the Model's Response\n",
    "\n",
    "This line sends a prompt to the OpenAI model using the invoke method. The prompt here is \"Ge mig ett gott råd\", which is Swedish for \"Give me some good advice\". The await keyword ensures that we wait for the model's response before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dd3081",
   "metadata": {},
   "outputs": [],
   "source": [
    "console.log(response.content);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3763d74b",
   "metadata": {},
   "source": [
    "**This technique is a very basic example of a usage of OpenAI GPT model useful for building interactive applications, chatbots, or any system that requires dynamic generation of text based on user input.**\n",
    "\n",
    "Let's look at this code as a whole: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d4fa6f6-0eb5-494c-b1d4-beaaa5f63c50",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "401 Incorrect API key provided: your_ope********here. You can find your API key at https://platform.openai.com/account/api-keys.",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "Error: 401 Incorrect API key provided: your_ope********here. You can find your API key at https://platform.openai.com/account/api-keys.",
      "    at Function.generate (file:///tmp/tomek/.cache/deno/npm/registry.npmjs.org/openai/4.56.0/error.mjs:44:20)",
      "    at OpenAI.makeStatusError (file:///tmp/tomek/.cache/deno/npm/registry.npmjs.org/openai/4.56.0/core.mjs:268:25)",
      "    at OpenAI.makeRequest (file:///tmp/tomek/.cache/deno/npm/registry.npmjs.org/openai/4.56.0/core.mjs:311:30)",
      "    at eventLoopTick (ext:core/01_core.js:174:7)",
      "    at async file:///tmp/tomek/.cache/deno/npm/registry.npmjs.org/@langchain/openai/0.0.10/dist/chat_models.js:628:29",
      "    at async RetryOperation._fn (file:///tmp/tomek/.cache/deno/npm/registry.npmjs.org/p-retry/4.6.2/index.js:50:12)"
     ]
    }
   ],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "\n",
    "const model = new ChatOpenAI({\n",
    "  modelName: \"gpt-4o\",\n",
    "});\n",
    "const response = await model.invoke('Ge mig ett gott råd');\n",
    "console.log(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9449027e",
   "metadata": {},
   "source": [
    "### Enhanced Model Interaction with Contextual Messages\n",
    "\n",
    "LangChain.js allows for more sophisticated interactions with language models by using SystemMessage and HumanMessage to provide context and instructions. This code demonstrates how to set context and guide the language model using SystemMessage and HumanMessage, resulting in more relevant and accurate responses. By providing clear instructions and user queries, you can enhance the interaction quality with the language model. \n",
    "\n",
    "Here’s how to implement and understand this approach:\n",
    "\n",
    "1. **Importing Required Classes**\n",
    "     - ChatOpenAI: Facilitates interaction with the OpenAI model.\n",
    "     - HumanMessage & SystemMessage: Define the types of messages to send.\n",
    "2. **Instantiate ChatOpenAI with the modelName parameter set to \"gpt-4o\".**\n",
    "3. **Defining the System and Human Message-**\n",
    "     - SystemMessage provides context: Specifies that the assistant is a career coach for programmers and system developers, ensuring polite and correct Swedish responses.\n",
    "     - HumanMessage contains the user query: \"Ge mig ett gott råd\" (Give me some good advice).\n",
    "4. **Sending Messages to the Model.**\n",
    "     - Use the invoke method to send both the system and human messages to the model and await the response.\n",
    "5. **Log the content of the model's response to the console.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f44e6955-82fd-4f2c-bfa4-0095a19ff8c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "401 Incorrect API key provided: your_ope********here. You can find your API key at https://platform.openai.com/account/api-keys.",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "Error: 401 Incorrect API key provided: your_ope********here. You can find your API key at https://platform.openai.com/account/api-keys.",
      "    at Function.generate (file:///tmp/tomek/.cache/deno/npm/registry.npmjs.org/openai/4.56.0/error.mjs:44:20)",
      "    at OpenAI.makeStatusError (file:///tmp/tomek/.cache/deno/npm/registry.npmjs.org/openai/4.56.0/core.mjs:268:25)",
      "    at OpenAI.makeRequest (file:///tmp/tomek/.cache/deno/npm/registry.npmjs.org/openai/4.56.0/core.mjs:311:30)",
      "    at eventLoopTick (ext:core/01_core.js:174:7)",
      "    at async file:///tmp/tomek/.cache/deno/npm/registry.npmjs.org/@langchain/openai/0.0.10/dist/chat_models.js:628:29",
      "    at async RetryOperation._fn (file:///tmp/tomek/.cache/deno/npm/registry.npmjs.org/p-retry/4.6.2/index.js:50:12)"
     ]
    }
   ],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { HumanMessage, SystemMessage } from \"@langchain/core/messages\";\n",
    "const model = new ChatOpenAI({\n",
    "  modelName: \"gpt-4o\",\n",
    "});\n",
    "const systemMessage = new SystemMessage({\n",
    "  content: 'Du är en kariärrcoach med fokus på programmerare och systemutvecklare. Du är inkännande och trevlig. Dina svar är alltid på korrekt svenska'\n",
    "});\n",
    "const input = new HumanMessage({content: \"Ge mig ett gott råd\"});\n",
    "const response = await model.invoke([\n",
    "  systemMessage, input\n",
    "]);\n",
    "\n",
    "console.log(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b438d5",
   "metadata": {},
   "source": [
    "### Extending Context with Prompt Templates\n",
    "LangChain.js provides SystemMessagePromptTemplate and HumanMessagePromptTemplate to further refine the context and instructions given to the model. This allows for even more specific guidance and tailored responses.\n",
    "\n",
    "This example demonstrates how to use `SystemMessagePromptTemplate` and `HumanMessagePromptTemplate`  classes to provide more detailed and context-specific instructions to the model. By defining templates and introducing placeholders, you can create dynamic and flexible interactions, allowing for more precise and tailored responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc69a5ea-c73c-4545-95e3-01d5306e6747",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "import {\n",
    "  ChatPromptTemplate,\n",
    "  SystemMessagePromptTemplate,\n",
    "  HumanMessagePromptTemplate,\n",
    "} from \"@langchain/core/prompts\";\n",
    "\n",
    "const systemMessagePromptTemplate = SystemMessagePromptTemplate.fromTemplate(\n",
    "  \"Du är en kariärrcoach med fokus på {occupation}. Du är {attitude}. Dina svar är alltid på {language}\"\n",
    ");\n",
    "\n",
    "const humanMessagePromptTemplate = HumanMessagePromptTemplate.fromTemplate(\n",
    "  \"Ge mig ett gott råd om {topic}\"\n",
    ");\n",
    "\n",
    "const promptFromMessages = ChatPromptTemplate.fromMessages([\n",
    "  systemMessagePromptTemplate,\n",
    "  humanMessagePromptTemplate,\n",
    "]);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7630f5ac",
   "metadata": {},
   "source": [
    "You can easily modify the topic parameter in the HumanMessagePromptTemplate to request advice on various skills:\n",
    "\n",
    "- Soft Skills: { topic: \"mjuka färdigheter\" }\n",
    "- Technical Skills: { topic: \"tekniska färdigheter\" }\n",
    "- AI Skills: { topic: \"AI färdigheter\" }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a296a62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "const model = new ChatOpenAI({\n",
    "  modelName: \"gpt-4o\",\n",
    "});\n",
    "const chain = promptFromMessages.pipe(model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95e6b922-796f-458a-97f8-cb44b6fbb83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunnableSequence {\n",
      "  lc_serializable: true,\n",
      "  lc_kwargs: {\n",
      "    first: ChatPromptTemplate {\n",
      "      lc_serializable: true,\n",
      "      lc_kwargs: {\n",
      "        inputVariables: [ \"occupation\", \"attitude\", \"language\", \"topic\" ],\n",
      "        promptMessages: [ [SystemMessagePromptTemplate], [HumanMessagePromptTemplate] ],\n",
      "        partialVariables: [Object: null prototype] {}\n",
      "      },\n",
      "      lc_runnable: true,\n",
      "      name: undefined,\n",
      "      lc_namespace: [ \"langchain_core\", \"prompts\", \"chat\" ],\n",
      "      inputVariables: [ \"occupation\", \"attitude\", \"language\", \"topic\" ],\n",
      "      outputParser: undefined,\n",
      "      partialVariables: [Object: null prototype] {},\n",
      "      promptMessages: [\n",
      "        SystemMessagePromptTemplate {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_runnable: true,\n",
      "          name: undefined,\n",
      "          lc_namespace: [Array],\n",
      "          prompt: [PromptTemplate]\n",
      "        },\n",
      "        HumanMessagePromptTemplate {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_runnable: true,\n",
      "          name: undefined,\n",
      "          lc_namespace: [Array],\n",
      "          prompt: [PromptTemplate]\n",
      "        }\n",
      "      ],\n",
      "      validateTemplate: true\n",
      "    },\n",
      "    last: ChatOpenAI {\n",
      "      lc_serializable: true,\n",
      "      lc_kwargs: { callbacks: undefined, modelName: \"gpt-4o\" },\n",
      "      lc_runnable: true,\n",
      "      name: undefined,\n",
      "      verbose: false,\n",
      "      callbacks: undefined,\n",
      "      tags: [],\n",
      "      metadata: {},\n",
      "      caller: AsyncCaller {\n",
      "        maxConcurrency: Infinity,\n",
      "        maxRetries: 6,\n",
      "        onFailedAttempt: [Function: defaultFailedAttemptHandler],\n",
      "        queue: PQueue {\n",
      "          _events: Events <Complex prototype> {},\n",
      "          _eventsCount: 0,\n",
      "          _intervalCount: 0,\n",
      "          _intervalEnd: 0,\n",
      "          _pendingCount: 0,\n",
      "          _resolveEmpty: [Function: empty],\n",
      "          _resolveIdle: [Function: empty],\n",
      "          _carryoverConcurrencyCount: false,\n",
      "          _isIntervalIgnored: true,\n",
      "          _intervalCap: Infinity,\n",
      "          _interval: 0,\n",
      "          _queue: [PriorityQueue],\n",
      "          _queueClass: [class PriorityQueue],\n",
      "          _concurrency: Infinity,\n",
      "          _intervalId: undefined,\n",
      "          _timeout: undefined,\n",
      "          _throwOnTimeout: false,\n",
      "          _isPaused: false\n",
      "        }\n",
      "      },\n",
      "      cache: undefined,\n",
      "      _encoding: undefined,\n",
      "      lc_namespace: [ \"langchain\", \"chat_models\", \"openai\" ],\n",
      "      temperature: 1,\n",
      "      topP: 1,\n",
      "      frequencyPenalty: 0,\n",
      "      presencePenalty: 0,\n",
      "      n: 1,\n",
      "      logitBias: undefined,\n",
      "      modelName: \"gpt-4o\",\n",
      "      modelKwargs: {},\n",
      "      stop: undefined,\n",
      "      user: undefined,\n",
      "      timeout: undefined,\n",
      "      streaming: false,\n",
      "      maxTokens: undefined,\n",
      "      openAIApiKey: \"your_openai_key_here\",\n",
      "      azureOpenAIApiVersion: undefined,\n",
      "      azureOpenAIApiKey: undefined,\n",
      "      azureOpenAIApiInstanceName: undefined,\n",
      "      azureOpenAIApiDeploymentName: undefined,\n",
      "      azureOpenAIBasePath: undefined,\n",
      "      organization: undefined,\n",
      "      client: undefined,\n",
      "      clientConfig: {\n",
      "        apiKey: \"your_openai_key_here\",\n",
      "        organization: undefined,\n",
      "        baseURL: undefined,\n",
      "        dangerouslyAllowBrowser: true,\n",
      "        defaultHeaders: undefined,\n",
      "        defaultQuery: undefined\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  lc_runnable: true,\n",
      "  name: undefined,\n",
      "  first: ChatPromptTemplate {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: {\n",
      "      inputVariables: [ \"occupation\", \"attitude\", \"language\", \"topic\" ],\n",
      "      promptMessages: [\n",
      "        SystemMessagePromptTemplate {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_runnable: true,\n",
      "          name: undefined,\n",
      "          lc_namespace: [Array],\n",
      "          prompt: [PromptTemplate]\n",
      "        },\n",
      "        HumanMessagePromptTemplate {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_runnable: true,\n",
      "          name: undefined,\n",
      "          lc_namespace: [Array],\n",
      "          prompt: [PromptTemplate]\n",
      "        }\n",
      "      ],\n",
      "      partialVariables: [Object: null prototype] {}\n",
      "    },\n",
      "    lc_runnable: true,\n",
      "    name: undefined,\n",
      "    lc_namespace: [ \"langchain_core\", \"prompts\", \"chat\" ],\n",
      "    inputVariables: [ \"occupation\", \"attitude\", \"language\", \"topic\" ],\n",
      "    outputParser: undefined,\n",
      "    partialVariables: [Object: null prototype] {},\n",
      "    promptMessages: [\n",
      "      SystemMessagePromptTemplate {\n",
      "        lc_serializable: true,\n",
      "        lc_kwargs: { prompt: [PromptTemplate] },\n",
      "        lc_runnable: true,\n",
      "        name: undefined,\n",
      "        lc_namespace: [ \"langchain_core\", \"prompts\", \"chat\" ],\n",
      "        prompt: PromptTemplate {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_runnable: true,\n",
      "          name: undefined,\n",
      "          lc_namespace: [Array],\n",
      "          inputVariables: [Array],\n",
      "          outputParser: undefined,\n",
      "          partialVariables: undefined,\n",
      "          templateFormat: \"f-string\",\n",
      "          template: \"Du är en kariärrcoach med fokus på {occupation}. Du är {attitude}. Dina svar är alltid på {language}\",\n",
      "          validateTemplate: true\n",
      "        }\n",
      "      },\n",
      "      HumanMessagePromptTemplate {\n",
      "        lc_serializable: true,\n",
      "        lc_kwargs: { prompt: [PromptTemplate] },\n",
      "        lc_runnable: true,\n",
      "        name: undefined,\n",
      "        lc_namespace: [ \"langchain_core\", \"prompts\", \"chat\" ],\n",
      "        prompt: PromptTemplate {\n",
      "          lc_serializable: true,\n",
      "          lc_kwargs: [Object],\n",
      "          lc_runnable: true,\n",
      "          name: undefined,\n",
      "          lc_namespace: [Array],\n",
      "          inputVariables: [Array],\n",
      "          outputParser: undefined,\n",
      "          partialVariables: undefined,\n",
      "          templateFormat: \"f-string\",\n",
      "          template: \"Ge mig ett gott råd om {topic}\",\n",
      "          validateTemplate: true\n",
      "        }\n",
      "      }\n",
      "    ],\n",
      "    validateTemplate: true\n",
      "  },\n",
      "  middle: [],\n",
      "  last: ChatOpenAI {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: { callbacks: undefined, modelName: \"gpt-4o\" },\n",
      "    lc_runnable: true,\n",
      "    name: undefined,\n",
      "    verbose: false,\n",
      "    callbacks: undefined,\n",
      "    tags: [],\n",
      "    metadata: {},\n",
      "    caller: AsyncCaller {\n",
      "      maxConcurrency: Infinity,\n",
      "      maxRetries: 6,\n",
      "      onFailedAttempt: [Function: defaultFailedAttemptHandler],\n",
      "      queue: PQueue {\n",
      "        _events: Events <[Object: null prototype] {}> {},\n",
      "        _eventsCount: 0,\n",
      "        _intervalCount: 0,\n",
      "        _intervalEnd: 0,\n",
      "        _pendingCount: 0,\n",
      "        _resolveEmpty: [Function: empty],\n",
      "        _resolveIdle: [Function: empty],\n",
      "        _carryoverConcurrencyCount: false,\n",
      "        _isIntervalIgnored: true,\n",
      "        _intervalCap: Infinity,\n",
      "        _interval: 0,\n",
      "        _queue: PriorityQueue { _queue: [] },\n",
      "        _queueClass: [class PriorityQueue],\n",
      "        _concurrency: Infinity,\n",
      "        _intervalId: undefined,\n",
      "        _timeout: undefined,\n",
      "        _throwOnTimeout: false,\n",
      "        _isPaused: false\n",
      "      }\n",
      "    },\n",
      "    cache: undefined,\n",
      "    _encoding: undefined,\n",
      "    lc_namespace: [ \"langchain\", \"chat_models\", \"openai\" ],\n",
      "    temperature: 1,\n",
      "    topP: 1,\n",
      "    frequencyPenalty: 0,\n",
      "    presencePenalty: 0,\n",
      "    n: 1,\n",
      "    logitBias: undefined,\n",
      "    modelName: \"gpt-4o\",\n",
      "    modelKwargs: {},\n",
      "    stop: undefined,\n",
      "    user: undefined,\n",
      "    timeout: undefined,\n",
      "    streaming: false,\n",
      "    maxTokens: undefined,\n",
      "    openAIApiKey: \"your_openai_key_here\",\n",
      "    azureOpenAIApiVersion: undefined,\n",
      "    azureOpenAIApiKey: undefined,\n",
      "    azureOpenAIApiInstanceName: undefined,\n",
      "    azureOpenAIApiDeploymentName: undefined,\n",
      "    azureOpenAIBasePath: undefined,\n",
      "    organization: undefined,\n",
      "    client: undefined,\n",
      "    clientConfig: {\n",
      "      apiKey: \"your_openai_key_here\",\n",
      "      organization: undefined,\n",
      "      baseURL: undefined,\n",
      "      dangerouslyAllowBrowser: true,\n",
      "      defaultHeaders: undefined,\n",
      "      defaultQuery: undefined\n",
      "    }\n",
      "  },\n",
      "  lc_namespace: [ \"langchain_core\", \"runnables\" ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "console.log(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3354312-4140-4bb3-bfc6-4d7254b75a35",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "401 Incorrect API key provided: your_ope********here. You can find your API key at https://platform.openai.com/account/api-keys.",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "Error: 401 Incorrect API key provided: your_ope********here. You can find your API key at https://platform.openai.com/account/api-keys.",
      "    at Function.generate (file:///tmp/tomek/.cache/deno/npm/registry.npmjs.org/openai/4.56.0/error.mjs:44:20)",
      "    at OpenAI.makeStatusError (file:///tmp/tomek/.cache/deno/npm/registry.npmjs.org/openai/4.56.0/core.mjs:268:25)",
      "    at OpenAI.makeRequest (file:///tmp/tomek/.cache/deno/npm/registry.npmjs.org/openai/4.56.0/core.mjs:311:30)",
      "    at eventLoopTick (ext:core/01_core.js:174:7)",
      "    at async file:///tmp/tomek/.cache/deno/npm/registry.npmjs.org/@langchain/openai/0.0.10/dist/chat_models.js:628:29",
      "    at async RetryOperation._fn (file:///tmp/tomek/.cache/deno/npm/registry.npmjs.org/p-retry/4.6.2/index.js:50:12)"
     ]
    }
   ],
   "source": [
    "const response = await chain.invoke({\n",
    "  occupation: \"socialarbetare\",\n",
    "  topic: \"lagstiftning\",\n",
    "  attitude: \"arg och tvär\",\n",
    "  language: \"förortsslang\",\n",
    "});\n",
    "\n",
    "console.log(response.content);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4065b95-4ea4-45cb-af66-195e8229b3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { RunnableSequence } from \"@langchain/core/runnables\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "const outputParser = new StringOutputParser\n",
    "\n",
    "const adviceChain = RunnableSequence.from([\n",
    "    promptFromMessages,\n",
    "    model,\n",
    "    outputParser\n",
    "])\n",
    "const stream = await adviceChain.invoke({\n",
    "    occupation: \"programmerare och systemutvecklare\",\n",
    "  topic: \"utveckling av AI applikationer med LangChainJS\",\n",
    "  attitude: \"inkännande\",\n",
    "  language: \"svenska\",})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57f2ba3-d28b-44a2-9465-b396cf1d4583",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
